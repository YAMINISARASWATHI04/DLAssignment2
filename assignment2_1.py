# -*- coding: utf-8 -*-
"""Assignment2-1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xUtGeJ7pJn_bnNe0f1-M0GKUrtVReoP6
"""

!pip install transformers datasets tqdm
!pip install torch  # or install with CUDA for GPU: pip install torch torchvision torchaudio
!pip install torchvision torchaudio

import kagglehub

# Download latest version
path = kagglehub.dataset_download("paultimothymooney/poetry")

print("Path to dataset files:", path)

import os

dataset_path = "/root/.cache/kagglehub/datasets/paultimothymooney/poetry/versions/16"
print(os.listdir(dataset_path))

import os

# Path to your lyrics folder
lyrics_dir = "/root/.cache/kagglehub/datasets/paultimothymooney/poetry/versions/16"

# List of all your lyric files
lyric_files = ['kanye.txt', 'paul-simon.txt', 'radiohead.txt', 'missy-elliott.txt', 'bruce-springsteen.txt',
               'lin-manuel-miranda.txt', 'cake.txt', 'janisjoplin.txt', 'nicki-minaj.txt', 'alicia-keys.txt',
               'bieber.txt', 'amy-winehouse.txt', 'adele.txt', 'disney.txt', 'bob-marley.txt', 'rihanna.txt',
               'patti-smith.txt', 'lil-wayne.txt', 'Lil_Wayne.txt', 'eminem.txt', 'dickinson.txt', 'kanye-west.txt',
               'nickelback.txt', 'dj-khaled.txt', 'notorious-big.txt', 'nirvana.txt', 'michael-jackson.txt',
               'britney-spears.txt', 'dr-seuss.txt', 'r-kelly.txt', 'drake.txt', 'bob-dylan.txt', 'lady-gaga.txt',
               'Kanye_West.txt', 'prince.txt', 'joni-mitchell.txt', 'bjork.txt', 'dolly-parton.txt', 'bruno-mars.txt',
               'blink-182.txt', 'johnny-cash.txt', 'notorious_big.txt', 'al-green.txt', 'nursery_rhymes.txt',
               'ludacris.txt', 'leonard-cohen.txt', 'jimi-hendrix.txt', 'beatles.txt', 'lorde.txt']

# Combine all lyrics into one list
lyrics_data = []

for file_name in lyric_files:
    full_path = os.path.join(lyrics_dir, file_name)
    with open(full_path, 'r', encoding='utf-8', errors='ignore') as f:
        text = f.read().strip()
        if text:
            lyrics_data.append(text)

print("Total songs loaded:", len(lyrics_data))

from datasets import Dataset

dataset = Dataset.from_dict({"text": lyrics_data})
dataset = dataset.train_test_split(test_size=0.1)

from transformers import GPT2LMHeadModel, GPT2Tokenizer

model_name = "gpt2"
tokenizer = GPT2Tokenizer.from_pretrained(model_name)
tokenizer.pad_token = tokenizer.eos_token

model = GPT2LMHeadModel.from_pretrained(model_name)

def tokenize_function(examples):
    # The labels for language modeling are the input_ids shifted to the right.
    # We need to add them to the input dictionary.
    inputs = tokenizer(examples["text"], truncation=True, padding="max_length", max_length=512)
    inputs["labels"] = inputs["input_ids"].copy()  # Labels are the same as input_ids for language modeling
    return inputs

tokenized_dataset = dataset.map(tokenize_function, batched=True, remove_columns=["text"])

from transformers import Trainer, TrainingArguments

training_args = TrainingArguments(
    output_dir="./lyrics-gpt2-results",
    overwrite_output_dir=True,
    num_train_epochs=3,
    per_device_train_batch_size=2,
    save_steps=500,
    save_total_limit=2,
    prediction_loss_only=True,
    logging_dir='./logs',
    logging_steps=100,
)

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=tokenized_dataset["train"],
    eval_dataset=tokenized_dataset["test"]
)

trainer.train()

prompt = "The night was dark and full of stars"
inputs = tokenizer(prompt, return_tensors="pt").to(model.device)

output = model.generate(
    **inputs,
    max_length=100,
    num_return_sequences=1,
    no_repeat_ngram_size=2,
    temperature=0.9,
    top_k=50,
    top_p=0.95,
    do_sample=True,
    early_stopping=True
)

print(tokenizer.decode(output[0], skip_special_tokens=True))

model.save_pretrained("./lyrics-gpt2")
tokenizer.save_pretrained("./lyrics-gpt2")

